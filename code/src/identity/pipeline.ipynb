{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from create_errors import introduce_errors\n",
    "import aspell\n",
    "\n",
    "from transformers import TFAutoModelForSeq2SeqLM, DataCollatorForSeq2Seq \n",
    "from transformers import TFEncoderDecoderModel, BertTokenizer\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.json') as json_file:\n",
    "    config = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_MODEL = config['model']\n",
    "DATA_PATHS = config['data_paths']\n",
    "NUM_PARALLEL = config['num_parallel']\n",
    "BATCH_SIZE_PER_REPLICE = config['batch_size_per_replica']\n",
    "MAX_LENGTH = config['max_length']\n",
    "STEPS_PER_EPOCH = config['steps_per_epoch']\n",
    "EPOCHS = config['epochs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Batch size per replica: {BATCH_SIZE_PER_REPLICE}\")\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: %d' % strategy.num_replicas_in_sync)\n",
    "BATCH_SIZE = BATCH_SIZE_PER_REPLICE * strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_name = config['optimizer']['name']\n",
    "optimizer_params = config['optimizer']['params']\n",
    "\n",
    "with strategy.scope():\n",
    "    if optimizer_name == 'Adam':\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=optimizer_params['lr'])\n",
    "    elif optimizer_name == 'AdamW':\n",
    "        optimizer = tf.keras.optimizers.experimental.AdamW(learning_rate=optimizer_params['lr'])\n",
    "    elif optimizer_name == 'Adafactor':\n",
    "        optimizer = tf.keras.optimizers.experimental.Adafactor(learning_rate=optimizer_params['lr'])\n",
    "    elif optimizer_name == 'AdaptiveAdam':\n",
    "        class LRSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "            def __init__(self, warmup_steps, d_model):\n",
    "                self.warmup_steps = tf.cast(warmup_steps, tf.float32)\n",
    "                self.d_model = tf.cast(d_model, tf.float32)\n",
    "\n",
    "            def __call__(self, step):\n",
    "                step = tf.cast(step, tf.float32)\n",
    "                lr = (1.0/tf.math.sqrt(self.d_model)) * tf.math.minimum(1.0 / tf.math.sqrt(step), (1.0 / tf.math.sqrt(self.warmup_steps)) * ((1.0 * step) / self.warmup_steps))\n",
    "                return lr\n",
    "\n",
    "        lr = LRSchedule(optimizer_params['warmup_steps'], MAX_LENGTH)\n",
    "        beta1 = optimizer_params['beta1']\n",
    "        beta2 = optimizer_params['beta2']\n",
    "        epsilon = optimizer_params['epsilon']\n",
    "        optimizer = tf.keras.optimizers.Adam(\n",
    "            learning_rate=lr,\n",
    "            beta_1=beta1,\n",
    "            beta_2=beta2,\n",
    "            epsilon=epsilon)\n",
    "\n",
    "with strategy.scope(): \n",
    "    loss = None   \n",
    "    if config['loss'] == \"SCC\":\n",
    "        loss = tf.keras.losses.SparseCategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = config['lang']\n",
    "token_file = config['token_file']\n",
    "tokens = introduce_errors.get_token_vocabulary(token_file)\n",
    "characters = introduce_errors.get_char_vocabulary(lang)\n",
    "aspell_speller = aspell.Speller('lang', lang)\n",
    "token_err_distribution = config['token_err_distribution']\n",
    "char_err_distribution = config['char_err_distribution']\n",
    "token_err_prob = config['token_err_prob']   \n",
    "char_err_prob = config['char_err_prob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(config['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenized_sentences(error_line, label_line):\n",
    "    error_line = error_line.decode('utf-8')\n",
    "    label_line = label_line.decode('utf-8')\n",
    "    tokenized = tokenizer(error_line, text_target=label_line, max_length=MAX_LENGTH, padding='max_length', truncation=True, return_tensors=\"tf\")\n",
    "    return tokenized['input_ids'], tokenized['attention_mask'], tokenized['labels']\n",
    "\n",
    "def create_error_line(line):\n",
    "    error_line = line\n",
    "    label_line = line\n",
    "    input_ids, attention_mask, labels = tf.numpy_function(get_tokenized_sentences, inp=[error_line, label_line], Tout=[tf.int32, tf.int32, tf.int32])\n",
    "    decoder_input_ids = tf.roll(labels, shift=1, axis=1)\n",
    "    dato = {\n",
    "        'input_ids': input_ids[0],\n",
    "        'attention_mask': attention_mask[0],\n",
    "        'decoder_input_ids': decoder_input_ids[0],\n",
    "        'labels': labels[0]\n",
    "    }\n",
    "    return dato\n",
    "\n",
    "def ensure_shapes(input_dict):\n",
    "    return {key: tf.ensure_shape(val, (MAX_LENGTH)) for key, val in input_dict.items()}\n",
    "\n",
    "def split_features_and_labels(input_batch):\n",
    "    features = {key: tensor for key, tensor in input_batch.items() if key in ['input_ids', 'attention_mask', 'decoder_input_ids']}\n",
    "    labels = {key: tensor for key, tensor in input_batch.items() if key in ['labels']}\n",
    "    if len(features) == 1:\n",
    "        features = list(features.values())[0]\n",
    "    if len(labels) == 1:\n",
    "        labels = list(labels.values())[0]\n",
    "    if isinstance(labels, dict) and len(labels) == 0:\n",
    "        return features\n",
    "    else:\n",
    "        return features, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.TextLineDataset(DATA_PATHS, num_parallel_reads=NUM_PARALLEL)\n",
    "\n",
    "dataset = dataset.map(create_error_line, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataset = dataset.map(ensure_shapes, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataset = dataset.map(split_features_and_labels, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataset = dataset.ignore_errors()\n",
    "dataset = dataset.shuffle(500)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    if config[\"pretrained\"]:\n",
    "        model = TFAutoModelForSeq2SeqLM.from_pretrained(config['model'])\n",
    "    else:\n",
    "        config = AutoConfig.from_pretrained(config['model'])\n",
    "        model = TFAutoModelForSeq2SeqLM.from_config(config)\n",
    "    \n",
    "    if loss:\n",
    "        model.compile(optimizer=optimizer, loss=loss)\n",
    "    else:\n",
    "        model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenzer = tokenizer\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % 10 == 0:\n",
    "            try:\n",
    "                sentences = [\n",
    "                    \"Mam rad svoju mamkinku .\",\n",
    "                    \"Moj pseik je moc roztomilý .\",\n",
    "                    \"Nejim zelneou zeleninu .\",\n",
    "                    \"Temé čelo mu se pokrylo potem .\",\n",
    "                    \"Vypadalo to , že každou omdlí .\",\n",
    "                    \"Bože , dEe , ty vypadáš bječně ! \"\n",
    "                ]\n",
    "                print()\n",
    "                for sentence in sentences: \n",
    "                    tokenized_sentence = tokenizer(sentence, max_length=MAX_LENGTH, padding='max_length', truncation=True, return_tensors=\"tf\")\n",
    "                    output = model.generate(tokenized_sentence['input_ids'])\n",
    "                    print(tokenizer.decode(output[0]))\n",
    "                    print()\n",
    "            except:\n",
    "                print(\"No predictions...\")\n",
    "\n",
    "callbacks = [\n",
    "    Evaluation(tokenizer=tokenizer),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=config['log_file'], profile_batch=config['profile_batch']),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=config['model_checkpoint_path'], save_weights_only=True, save_freq='epoch')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.utils.SidecarEvaluator(\n",
    "#     model=model,\n",
    "#     data=dataset,\n",
    "#     # dir for training-saved checkpoint\n",
    "#     checkpoint_dir='/tmp/checkpoint_dir',\n",
    "#     steps=None,  # Eval until dataset is exhausted\n",
    "#     max_evaluations=None,  # The evaluation needs to be stopped manually\n",
    "#     callbacks=[tf.keras.callbacks.TensorBoard(log_dir='/tmp/log_dir')]\n",
    "# ).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if STEPS_PER_EPOCH:\n",
    "    model.fit(dataset, callbacks=callbacks, epochs=EPOCHS, steps_per_epoch=STEPS_PER_EPOCH)\n",
    "else:\n",
    "    model.fit(dataset, callbacks=callbacks, epochs=EPOCHS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_filepath = './tmp/checkpoint/' # must be folder (/ at the end)\n",
    "\n",
    "# model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
