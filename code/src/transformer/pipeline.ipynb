{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from transformers import TFAutoModelForSeq2SeqLM\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoConfig\n",
    "import json\n",
    "\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "from utils import load_data\n",
    "from utils import introduce_errors \n",
    "\n",
    "from multiprocessing import Process, Manager\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.json') as json_file:\n",
    "    config = json.load(json_file)\n",
    "\n",
    "SEED = config['seed']\n",
    "\n",
    "# data loading\n",
    "DATA_PATHS = config['data_paths']\n",
    "NUM_PARALLEL = config['num_parallel']\n",
    "MAX_LENGTH = config['max_length']\n",
    "SHUFFLE_BUFFER = config['shuffle_buffer']\n",
    "\n",
    "# model\n",
    "MODEL = config['model']\n",
    "TOKENIZER = config['tokenizer']\n",
    "FROM_CONFIG = config['from_config']\n",
    "STEPS_PER_EPOCH = config['steps_per_epoch']\n",
    "EPOCHS = config['epochs']\n",
    "\n",
    "# optimizer\n",
    "OPTIMIZER_NAME = config['optimizer']['name']\n",
    "OPTIMIZER_PARAMS = config['optimizer']['params']\n",
    "\n",
    "# loss\n",
    "LOSS = config['loss']\n",
    "\n",
    "# GEL config\n",
    "LANG = config['lang']\n",
    "TOKEN_FILE = config['token_file']\n",
    "TOKEN_ERR_DISTRIBUTION = config['token_err_distribution']\n",
    "CHAR_ERR_DISTRIBUTION = config['char_err_distribution']\n",
    "TOKEN_ERR_PROB = config['token_err_prob']   \n",
    "CHAR_ERR_PROB = config['char_err_prob']\n",
    "\n",
    "# logs\n",
    "LOG_FILE = config['log_file']\n",
    "PROFILE_BATCH = config['profile_batch']\n",
    "MODEL_CHECKPOINT_PATH = config['model_checkpoint_path']\n",
    "BACKUP_DIR =  config['backup_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(config['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = introduce_errors.get_token_vocabulary(TOKEN_FILE)\n",
    "characters = introduce_errors.get_char_vocabulary(LANG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading of dataset:\n",
    "\n",
    "# multiprocessing.set_start_method('spawn')   \n",
    "\n",
    "def split_features_and_labels(input_batch):\n",
    "    features = {key: tensor for key, tensor in input_batch.items() if key in ['input_ids', 'attention_mask', 'decoder_input_ids']}\n",
    "    labels = {key: tensor for key, tensor in input_batch.items() if key in ['labels']}\n",
    "    if len(features) == 1:\n",
    "        features = list(features.values())[0]\n",
    "    if len(labels) == 1:\n",
    "        labels = list(labels.values())[0]\n",
    "    if isinstance(labels, dict) and len(labels) == 0:\n",
    "        return features\n",
    "    else:\n",
    "        return features, labels\n",
    "\n",
    "manager = Manager()\n",
    "queue = manager.Queue(2 * NUM_PARALLEL)\n",
    "gel = load_data.GenereteErrorLine(\n",
    "        tokens, characters, LANG, \n",
    "        TOKEN_ERR_DISTRIBUTION, CHAR_ERR_DISTRIBUTION, \n",
    "        TOKEN_ERR_PROB, CHAR_ERR_PROB)\n",
    "\n",
    "process = Process(\n",
    "            target=load_data.data_generator, \n",
    "            args=(queue, DATA_PATHS, NUM_PARALLEL, gel, tokenizer, MAX_LENGTH,))\n",
    "\n",
    "process.start()\n",
    "    \n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: iter(queue.get, None),\n",
    "    output_types={\n",
    "                \"input_ids\": tf.int32,\n",
    "                \"attention_mask\": tf.int32,\n",
    "                \"labels\": tf.int32,\n",
    "                \"decoder_input_ids\": tf.int32\n",
    "            },\n",
    "    output_shapes={\n",
    "                \"input_ids\": (None, ),\n",
    "                \"attention_mask\": (None, ),\n",
    "                \"labels\": (None, ),\n",
    "                \"decoder_input_ids\": (None, )\n",
    "            })\n",
    "\n",
    "dataset = dataset.map(split_features_and_labels, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataset = dataset.shuffle(SHUFFLE_BUFFER)\n",
    "dataset = dataset.bucket_by_sequence_length(\n",
    "        element_length_func=lambda x, y: tf.shape(x['input_ids'])[0],\n",
    "        bucket_boundaries=[32, 64, 96],\n",
    "        bucket_batch_sizes=[84, 64, 60, 54]\n",
    ")\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy = mixed_precision.Policy('mixed_float16')\n",
    "# mixed_precision.set_global_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: %d' % strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    if OPTIMIZER_NAME == 'Adam':\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=OPTIMIZER_PARAMS['lr'])\n",
    "    elif OPTIMIZER_NAME == 'AdamW':\n",
    "        optimizer = tf.keras.optimizers.experimental.AdamW(learning_rate=OPTIMIZER_PARAMS['lr'])\n",
    "    elif OPTIMIZER_NAME == 'Adafactor':\n",
    "        optimizer = tf.keras.optimizers.experimental.Adafactor(learning_rate=OPTIMIZER_PARAMS['lr'])\n",
    "    elif OPTIMIZER_NAME == 'AdaptiveAdam':\n",
    "        class LRSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "            def __init__(self, warmup_steps, d_model):\n",
    "                self.warmup_steps = tf.cast(warmup_steps, tf.float32)\n",
    "                self.d_model = tf.cast(d_model, tf.float32)\n",
    "\n",
    "            def __call__(self, step):\n",
    "                step = tf.cast(step, tf.float32)\n",
    "                lr = (1.0/tf.math.sqrt(self.d_model)) * tf.math.minimum(1.0 / tf.math.sqrt(step), (1.0 / tf.math.sqrt(self.warmup_steps)) * ((1.0 * step) / self.warmup_steps))\n",
    "                return lr\n",
    "\n",
    "        lr = LRSchedule(OPTIMIZER_PARAMS['warmup_steps'], MAX_LENGTH)\n",
    "        beta1 = OPTIMIZER_PARAMS['beta1']\n",
    "        beta2 = OPTIMIZER_PARAMS['beta2']\n",
    "        epsilon = OPTIMIZER_PARAMS['epsilon']\n",
    "        optimizer = tf.keras.optimizers.Adam(\n",
    "            learning_rate=lr,\n",
    "            beta_1=beta1,\n",
    "            beta_2=beta2,\n",
    "            epsilon=epsilon)\n",
    "\n",
    "with strategy.scope(): \n",
    "    loss = None   \n",
    "    if LOSS == \"SCC\":\n",
    "        class MaskedSparseCategoricalCrossEntropy(tf.keras.losses.Loss):\n",
    "            # source: https://github.com/huggingface/transformers/blob/04ab5605fbb4ef207b10bf2772d88c53fc242e83/src/transformers/modeling_tf_utils.py#L210\n",
    "            def __init__(self, reduction=tf.keras.losses.Reduction.NONE, name=None):\n",
    "                super().__init__(reduction, name)\n",
    "                self.loss_func = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=reduction)\n",
    "            \n",
    "            def call(self, y_true, y_pred):\n",
    "                return self.hf_compute_loss(y_true, y_pred)\n",
    "\n",
    "            def hf_compute_loss(self, labels, logits):\n",
    "                unmasked_loss = self.loss_func(tf.nn.relu(labels), logits)\n",
    "                loss_mask = tf.cast(labels != -100, dtype=unmasked_loss.dtype)\n",
    "                masked_loss = unmasked_loss * loss_mask\n",
    "                reduced_masked_loss = tf.reduce_sum(masked_loss) / tf.reduce_sum(loss_mask)\n",
    "                return reduced_masked_loss\n",
    "        \n",
    "        loss = MaskedSparseCategoricalCrossEntropy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    if FROM_CONFIG:\n",
    "        config = AutoConfig.from_pretrained(MODEL)\n",
    "        model = TFAutoModelForSeq2SeqLM.from_config(config)\n",
    "    else:\n",
    "        model = TFAutoModelForSeq2SeqLM.from_pretrained(MODEL)\n",
    "    \n",
    "    if loss:\n",
    "        model.compile(optimizer=optimizer, loss=loss)\n",
    "    else:\n",
    "        model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.optimizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=os.path.join(MODEL_CHECKPOINT_PATH, 'ckpt-{epoch}/'),\n",
    "    save_weights_only=True,\n",
    "    save_freq=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backup = tf.keras.callbacks.BackupAndRestore(\n",
    "    backup_dir=BACKUP_DIR\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=LOG_FILE, \n",
    "    profile_batch=PROFILE_BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    model_checkpoint,\n",
    "    backup,\n",
    "    profiler\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if STEPS_PER_EPOCH:\n",
    "    model.fit(dataset, callbacks=callbacks, epochs=EPOCHS, steps_per_epoch=STEPS_PER_EPOCH)\n",
    "else:\n",
    "    model.fit(dataset, callbacks=callbacks, epochs=EPOCHS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     multiprocessing.set_start_method('spawn')\n",
    "#     main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
