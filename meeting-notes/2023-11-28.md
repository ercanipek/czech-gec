`bart-szn-2` - training - bart - AdamW - novy tokenizer - Kubova data (24. checkpoint)
`bart-szn-2-backup` - ulozeny 10. checkpoint

`bart-szn-3-params` - data 2017 - pipeline - puvodni introduce_errors - parametry pro kažení dat z Kubovo práce (16. checkpoint)
`bart-szn-3-params-copy` - ulozeny 10. checkpoint

(`bart-szn-3-new-errors` - data 2017 - pipeline - novy introduce_errors - parametry pro kažení dat z Kubovo práce)

---

- jeste chvili spustit `bart-szn-3-params` - mit starsi checkpoint -> Mam 25. checkpoint -> chci cca 40. nebo nejlepsi


- zkusit použít moje syntetická data při pretrainingu (mix s akcesem 1:2)

- zkusit nechat jeste bezet pipelinu pretrainingu (treba az z 40. checkpointu), a pak finetuning - (najit nejlepsi checkpoint mezi 26. a 40.)

- upravit rejection sampling - pridat random (takhle je to moc pravidelne)
    - dopsat do syntetickeho tvoreni

- nastroj na pretagovani - akcesových dat

- spustit evaluaci na geccc (separe pro jednotlivé domény) - micro/macro f1 score

- generování chyb - greedy search, zakázat mu jednou za čas nejpravděpodobnější token (bude složitější) - bad_words, diversity_penalty 