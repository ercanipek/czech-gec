`bart-szn-2` - training - bart - AdamW - novy tokenizer - Kubova data
`bart-szn-2-backup` - ulozeny 10. checkpoint

`bart-szn-3-params` - data 2017 - pipeline - puvodni introduce_errors - parametry pro kažení dat z Kubovo práce
`bart-szn-3-params-copy` - ulozeny 10. checkpoint

`bart-szn-3-new-errors` - data 2017 - pipeline - novy introduce_errors - parametry pro kažení dat z Kubovo práce

---

- vygenerovat offline data z introduce_errors.py a porovnat s vysledky, ktere dostavam v automatickem vytvareni dat
  - kdyby se nerovnalo, tak spustit s puvodnim aspellem
  - `bart-szn-4-generated-data`

- zkusit trenovani s:
    "token_err_distribution": [0.7, 0.1, 0.1, 0.1, 0],
    "char_err_distribution": [0.2, 0.2, 0.2, 0.2, 0.2],
    `bart-szn-4-pipeline-zero`

- zapsat lr po nahrani checkpointu pro finetuning (pomer 1:2)
  - s nejlepsim vysledkem a s nejlepsi pipeline
  - nejlepsi vysledek:
    - `bart-szn-2-lr-finetuning-15M` (petr-bart-train-fine-15m)
  - nejlepsi pipeline:
    - `bart-szn-3-params-lr-finetuning-15M`

- pripadne zkusit jine pomery (1:1, 1:5, ...)
(- natrenovat model druhym smerem)

###
- urcite chceme tvorit typycke synteticke chyby

- vytvorit m2 file s "error - predicted" pomoci errant a pregenerovat akces (lze pomoci parallel_to_m2)
- nahradit edity za typicke chyby na m2 filech (bez errantu)
- pouzit compare_m2 "error - golden" a "error - predicted"

- vytvareni chyby -> vytvoreni editu
- chyby mit prehledne ve vice classach (napr)
- z vety -> list moznych editu konkretni chyby
- iteruji pres vsechny mozne chyby
- nad tim trida, ktera se bude starat v jakem procentu per token udelat danou chybu (rejection sampling - precist)
