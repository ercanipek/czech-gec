- vygenerovat offline data z introduce_errors.py a porovnat s vysledky, ktere dostavam v automatickem vytvareni dat
  - kdyby se nerovnalo, tak spustit s puvodnim aspellem

- zkusit trenovani s:
    "token_err_distribution": [0.7, 0.1, 0.1, 0.1, 0],
    "char_err_distribution": [0.2, 0.2, 0.2, 0.2, 0.2],

- zapsat lr po nahrani checkpointu pro finetuning
  - s nejlepsim vysledkem a s nejlepsi pipeline

- pripadne zkusit jine pomery (1:1, 1:5, ...)
- natrenovat model druhym smerem

- urcite chceme tvorit typycke synteticke chyby


- vytvorit m2 file s "error - predicted" pomoci errant a pregenerovat akces (lze pomoci parallel_to_m2)
- nahradit edity za typicke chyby na m2 filech
- pouzit compare_m2 "error - golden" a "error - predicted"

- vytvareni chyby -> vytvoreni editu
- chyby mit prehledne ve vice classach (napr)
- z vety -> list moznych editu konkretni chyby
- nad tim trida, ktera se bude starat v jakem procentu per token udelat danou chybu (rejection sampling - precist)
