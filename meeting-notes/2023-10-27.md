- zjistit, jestli je lr stejný nebo zmenšený

- analyza ceskych chyb
- opravidlo
- najit typicke chyby -> zkusit je generovat (replace)
- podivat se, jak funguje model (trenovany i dotrenovany) na typickych chybach

- trenovani mt5
- kdyby bylo GPU zkusit druhy smer

- zjistit, proč potom ještě tokenizujeme udpipe tokenizerem


1. Stáhnout další WMT (https://data.statmt.org/news-crawl/cs/)
2. Zkusit pustit trénování s 2017 daty a s více daty
    - `bart-szn-3-pipeline` - data 2017 - pipeline - puvodni introduce_errors
    - `bart-szn-3-more-data` - data 2017, 2018, 2019 - puvodni introduce_errors
3. Zjistit, jaké parametry se opravdu pužívali v Kubovo práci:
    - `bart-szn-3-params` - data 2017 - pipeline - puvodni introduce_errors - parametry pro kažení dat z Kubovo práce
    - `bart-szn-3-new-errors` - data 2017 - pipeline - novy introduce_errors - parametry pro kažení dat z Kubovo práce
4. Podívat se na lr po načtení
    - lr zůstává 5e-05, načtení optimizeru hodnotu přepíše zpět
    - `bart-szn-3-params-finetuning` - 15M dat - pipeline - puvodni introduce_errors - parametry pro kažení dat z Kubovo práce
5. Podívat se na Opravidlo a sepsat typické české chyby.
6. Projít generování chyb a vypisovat, pokud vytvořím typickou chybu.
7. Dopsat kód pro škálování typických českých chyb. (Rozvrhnout procentuální výskyt, pravděpodobnost takové chyby)
8. Nástroj, pro detekci typických chyb, které máme v evaluačních datech. 